{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI, TwitterPager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "#get crtdentials from twitter credentials text file sabved to same location as this\n",
    "#file. removed credentiasl to uplaod to github\n",
    "\n",
    "c_key = \"\"\n",
    "c_key_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "month_endpoint = \"https://api.twitter.com/1.1/tweets/search/30day/monthDev.json\"\n",
    "full_endpoint = \"https://api.twitter.com/1.1/tweets/search/fullarchive/fullDev.json\"\n",
    "VERIFY_CREDENTIALS_URL = 'https://api.twitter.com/1.1/account/verify_credentials.json'\n",
    "api = TwitterAPI(c_key,\n",
    "                c_key_secret,\n",
    "                access_token,\n",
    "                access_token_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full archive searches\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'fullDev'\n",
    "QUERY = '(computer OR Computer) (science OR Science)  lang:en'\n",
    "TAG = '-is:retweet place_country:us '\n",
    "i = 0\n",
    "TO_DATE = 3245425\n",
    "\n",
    "\n",
    "request_dict = {'query' : QUERY,\n",
    "                'tag' : TAG,\n",
    "                'toDate' : TO_DATE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAN18\n",
      "FEB18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5b5c0e8361b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PRODUCT = '30day'\n",
    "#LABEL = 'monthDev'\n",
    "#SEARCH_TERM = 'computer science OR Computer Science -filter:retweets'\n",
    "\n",
    "#used this to grab tweets for full  tweets database a year at a time by just changing the year \n",
    "#it grabbed 100 tweets from each month \n",
    "#for as many months as I was able with 50 requests\n",
    "i = 1\n",
    "TWEETS = []\n",
    "YEAR = '18'\n",
    "while i < 5000:\n",
    "    month = MONTH[i]+YEAR\n",
    "    TO_DATE = DATES_DICT[month]\n",
    "    request_dict = {'query' : QUERY,\n",
    "                    'tag' : TAG,\n",
    "                    'toDate' : TO_DATE}\n",
    "\n",
    "    r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL),\n",
    "                    request_dict)\n",
    "    for item in r:\n",
    "        TWEETS.append(item)\n",
    "    with open('test_tweets_'+month+'.txt', 'w') as file:\n",
    "        file.write(json.dumps(TWEETS, indent=4))\n",
    "    print(month)\n",
    "    i = i + 1\n",
    "    time.sleep(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFT_LONG = -91.179858\n",
    "PFT_LAT = 30.407750\n",
    "\n",
    "ULL_LONG = -92.018258\n",
    "ULL_LAT = 30.224502\n",
    "\n",
    "PRODUCT = '30day'\n",
    "LABEL = 'monthDev'\n",
    "QUERY = '(computer OR Computer) (science OR Science)  lang:en'\n",
    "TAG = '-is:retweet point_radius:[-92.018258,30.224502]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def iterate_request(request):\n",
    "        it = request.get_iterator()\n",
    "        for item in it:\n",
    "            yield item\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4fcd1b5a4945>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mpause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwait\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mwait\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PRODUCT = '30day'\n",
    "LABEL = 'monthDev'\n",
    "QUERY = '(computer OR Computer) (science OR Science)  lang:en'\n",
    "TAG = '-is:retweet point_radius:[-92.018258,30.224502,1]'\n",
    "\n",
    "#this is to use to get the most recent tweets from the past 30 days within a mile of the center of LSU\n",
    "i = 1\n",
    "tweets = []\n",
    "while(True):\n",
    "    wait = 5\n",
    "    start = time.time()\n",
    "    request_dict = {'query' : QUERY,\n",
    "                    'tag' : TAG}\n",
    "    \n",
    "    \n",
    "    #make request\n",
    "    r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL),\n",
    "                    request_dict)\n",
    "    print (i)\n",
    "    i = i + 1\n",
    "\n",
    "    for item in iterate_request(r):\n",
    "        tweets.append(item)\n",
    "    \n",
    "    #get token\n",
    "    cursor = -1\n",
    "    r_json = r.json()\n",
    "    if 'next' in r_json:\n",
    "        cursor = r_json['next']\n",
    "        elapsed = time.time() - start\n",
    "        pause = wait - elapsed if elapsed < wait else 0\n",
    "        time.sleep(pause)\n",
    "        \n",
    "    #check for next page of tweets if token is valid, if token is -1 quit running\n",
    "    while cursor != -1 and i < 100:\n",
    "        start = time.time()\n",
    "        #add token to request dict\n",
    "        request_dict['next'] = cursor\n",
    "        \n",
    "        #make request\n",
    "        r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL),\n",
    "                    request_dict)\n",
    "        print(i)\n",
    "        i = i + 1\n",
    "\n",
    "        #add items to tweet list\n",
    "        for item in iterate_request(r):\n",
    "            tweets.append(item)\n",
    "            \n",
    "        #get token\n",
    "        cursor = -1\n",
    "        r_json = r.json()\n",
    "        if 'next' in r_json:\n",
    "            cursor = r_json['next']\n",
    "            \n",
    "        #pause to ensure new request works\n",
    "        elapsed = time.time() - start\n",
    "        pause = wait - elapsed if elapsed < wait else 0\n",
    "        time.sleep(pause)\n",
    "        \n",
    "        \n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n",
    "#write results to file\n",
    "with open('text1.txt', 'w') as file:\n",
    "        file.write(json.dumps(tweets, indent=4))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#write results to file\n",
    "with open('text1.txt', 'w') as file:\n",
    "        file.write(json.dumps(tweets, indent=4))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Computer Science\" OR \"computer science\" -filter:retweets\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#used this to grab tweets for basic search, which is done by # of tweets not length of time, so \n",
    "#Twitter estimates it at 6-9 days worth of tweets included in basic search\n",
    "SEARCH_TERM = '\\\"Computer Science\" OR \"computer science\\\" -filter:retweets'\n",
    "print(SEARCH_TERM)\n",
    "n = 50\n",
    "tweets = []\n",
    "\n",
    "pager = TwitterPager(api, 'search/tweets', {'q': SEARCH_TERM})\n",
    "\n",
    "try:\n",
    "    for item in pager.get_iterator():\n",
    "        tweets.append(item)\n",
    "        if(len(tweets) % 100 == 0):\n",
    "            print(len(tweets))\n",
    "        if(len(tweets) > n):\n",
    "            break\n",
    "except:\n",
    "    print('exception happened')\n",
    "finally:\n",
    "    with open('standard_csc_tweets', 'w') as file:\n",
    "        file.write(json.dumps(tweets, indent=4))\n",
    "        print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#shazam OR #shazammovie) lang:en -filter:retweets\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Basic search for the hastag hellboy in english\n",
    "# no retweets only posts and replies.\n",
    "MIDDLE_BR_LAT= 30.440975\n",
    "MIDDLE_BR_LONG = -91.105336\n",
    "\n",
    "SEARCH_TERM = '(#shazam OR #shazammovie) lang:en -filter:retweets'\n",
    "print(SEARCH_TERM)\n",
    "n = 50\n",
    "tweets = []\n",
    "\n",
    "pager = TwitterPager(api, 'search/tweets', {'q': SEARCH_TERM})\n",
    "\n",
    "try:\n",
    "    for item in pager.get_iterator():\n",
    "        tweets.append(item)\n",
    "        if(len(tweets) % 100 == 0):\n",
    "            print(len(tweets))\n",
    "        if(len(tweets) > n):\n",
    "            break\n",
    "except:\n",
    "    print('exception happened')\n",
    "finally:\n",
    "    with open('test2', 'w') as file:\n",
    "        file.write(json.dumps(tweets, indent=4))\n",
    "        print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
