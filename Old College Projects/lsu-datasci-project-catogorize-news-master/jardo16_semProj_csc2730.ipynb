{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jake Ardoin semester project for CSC2730. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           authors       category       date  \\\n",
       "0  Melissa Jeltsen          CRIME 2018-05-26   \n",
       "1    Andy McDonald  ENTERTAINMENT 2018-05-26   \n",
       "2       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "3       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "4       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "\n",
       "                                            headline  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description  \n",
       "0  She left her husband. He killed their children...  \n",
       "1                           Of course it has a song.  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  \n",
       "4  The \"Dietland\" actress said using the bags is ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TA: CHANGE THIS FILE NAME TO THE LOCATION OF THE FILE YOU WISH TO READ FROM\n",
    "df = pd.read_json('/Users/PCnew/Documents/Datasets/News_Category_Dataset.json',\n",
    "                  lines=True)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted attributes TA: You can skip this if you used\n",
    "#the 20k.json file, thought just downloading the actual data\n",
    "#would be much simpler\n",
    "\n",
    "df1 = df.drop([\"authors\", \"date\", \"link\"], axis=1)\n",
    "df1.replace('', np.nan, inplace=True)\n",
    "df1 = df1.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105398, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my computer cant do 100k of these freaking things\n",
    "#TA: Chance this slice number to the number of examples\n",
    "#that you want to test for doing grading\n",
    "df1=df1[0:20000]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is explained at the end, it is to get rid of a category with only 1 example\n",
    "df1 = df1[df1.category != 'GOOD NEWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of y\n",
      "0            CRIME\n",
      "1    ENTERTAINMENT\n",
      "2    ENTERTAINMENT\n",
      "3    ENTERTAINMENT\n",
      "4    ENTERTAINMENT\n",
      "Name: category, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19999,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now that I've removed the blank spaces I'm left with 105398 rows of data. \n",
    "#first im going to define a few data groups I need for later\n",
    "#then i'll make Bag of WOrds out of the headline column + description column\n",
    "#this will be done over the next handful of cells so examples can be printed of each\n",
    "headline = df1[\"headline\"]\n",
    "description = df1[\"short_description\"]\n",
    "category = df1[\"category\"]\n",
    "\n",
    "\n",
    "y = category\n",
    "print(\"Sample of y\")\n",
    "print(y[0:5])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of X\n",
      "0    There Were 2 Mass Shootings In Texas Last Week...\n",
      "1    Will Smith Joins Diplo And Nicky Jam For The 2...\n",
      "2    Hugh Grant Marries For The First Time At Age 5...\n",
      "3    Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
      "4    Julianna Margulies Uses Donald Trump Poop Bags...\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19999,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here I combine the description and the title together into a single unit\n",
    "X = headline + \" \" + description\n",
    "print(\"Sample of X\")\n",
    "print(X[0:5])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(X,\n",
    "                                        y, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 24423)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#played with the variables to figure out the effects to decide \n",
    "#on which numbers to test in each variable of the grid_search\n",
    "vect = TfidfVectorizer(min_df = 0, max_df = 0.6 )\n",
    "docmatrix = vect.fit_transform(docs_train)\n",
    "docmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=10, max_df=0.1)),\n",
    "    ('svc', LinearSVC(C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.1, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__min_df': [0, 10], 'vect__max_df': [0.4, 0.3, 0.2], 'svc__C': [2, 1, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__min_df': [0, 10],\n",
    "    'vect__max_df': [0.4, 0.3, 0.2],\n",
    "    'svc__C': [2, 1, .1]\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, verbose=0)\n",
    "grid_search.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'vect__max_df': 0.3, 'vect__min_df': 0}\n"
     ]
    }
   ],
   "source": [
    "#Lets see what grid search has decided our best params are:\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "y_predicted = model.predict(docs_test)\n",
    "print(accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from every test are as follows. I used grid.scores_ because its a bit easier to read than cv_results_ \n",
    "I also included cv_results_ just for completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(data = grid_search.cv_results_)\n",
    "file = open(\"df_scores_semesterproject.pdf\", \"w\")\n",
    "file.write(str(df_scores))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svc__C  \\\n",
      "0        0.859183      0.075236         0.062490        0.000019            2   \n",
      "1        0.744985      0.049347         0.056253        0.007645            2   \n",
      "2        0.796692      0.013967         0.056231        0.007638            2   \n",
      "3        0.712332      0.015930         0.049988        0.006249            2   \n",
      "4        0.802926      0.044835         0.059367        0.006252            2   \n",
      "5        0.706088      0.011681         0.059360        0.006259            2   \n",
      "6        0.727951      0.012501         0.059370        0.006241            1   \n",
      "7        0.627987      0.006243         0.049987        0.006236            1   \n",
      "8        0.712335      0.012494         0.062481        0.000013            1   \n",
      "9        0.612552      0.006160         0.056230        0.007649            1   \n",
      "10       0.696709      0.007641         0.049995        0.006246            1   \n",
      "11       0.615470      0.021197         0.059369        0.006240            1   \n",
      "12       0.621741      0.006241         0.049986        0.006236          0.1   \n",
      "13       0.524882      0.007656         0.062486        0.000001          0.1   \n",
      "14       0.596730      0.006237         0.062494        0.000012          0.1   \n",
      "15       0.521763      0.021183         0.053101        0.007662          0.1   \n",
      "16       0.593621      0.000014         0.059362        0.006237          0.1   \n",
      "17       0.503001      0.006265         0.056236        0.007653          0.1   \n",
      "\n",
      "   param_vect__max_df param_vect__min_df  \\\n",
      "0                 0.4                  0   \n",
      "1                 0.4                 10   \n",
      "2                 0.3                  0   \n",
      "3                 0.3                 10   \n",
      "4                 0.2                  0   \n",
      "5                 0.2                 10   \n",
      "6                 0.4                  0   \n",
      "7                 0.4                 10   \n",
      "8                 0.3                  0   \n",
      "9                 0.3                 10   \n",
      "10                0.2                  0   \n",
      "11                0.2                 10   \n",
      "12                0.4                  0   \n",
      "13                0.4                 10   \n",
      "14                0.3                  0   \n",
      "15                0.3                 10   \n",
      "16                0.2                  0   \n",
      "17                0.2                 10   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'svc__C': 2, 'vect__max_df': 0.4, 'vect__min_...           0.660359   \n",
      "1   {'svc__C': 2, 'vect__max_df': 0.4, 'vect__min_...           0.616866   \n",
      "2   {'svc__C': 2, 'vect__max_df': 0.3, 'vect__min_...           0.662019   \n",
      "3   {'svc__C': 2, 'vect__max_df': 0.3, 'vect__min_...           0.615206   \n",
      "4   {'svc__C': 2, 'vect__max_df': 0.2, 'vect__min_...           0.648074   \n",
      "5   {'svc__C': 2, 'vect__max_df': 0.2, 'vect__min_...           0.608234   \n",
      "6   {'svc__C': 1, 'vect__max_df': 0.4, 'vect__min_...           0.666335   \n",
      "7   {'svc__C': 1, 'vect__max_df': 0.4, 'vect__min_...           0.634462   \n",
      "8   {'svc__C': 1, 'vect__max_df': 0.3, 'vect__min_...           0.665671   \n",
      "9   {'svc__C': 1, 'vect__max_df': 0.3, 'vect__min_...           0.635126   \n",
      "10  {'svc__C': 1, 'vect__max_df': 0.2, 'vect__min_...           0.654714   \n",
      "11  {'svc__C': 1, 'vect__max_df': 0.2, 'vect__min_...           0.623838   \n",
      "12  {'svc__C': 0.1, 'vect__max_df': 0.4, 'vect__mi...           0.629814   \n",
      "13  {'svc__C': 0.1, 'vect__max_df': 0.4, 'vect__mi...           0.629150   \n",
      "14  {'svc__C': 0.1, 'vect__max_df': 0.3, 'vect__mi...           0.630146   \n",
      "15  {'svc__C': 0.1, 'vect__max_df': 0.3, 'vect__mi...           0.629814   \n",
      "16  {'svc__C': 0.1, 'vect__max_df': 0.2, 'vect__mi...           0.621514   \n",
      "17  {'svc__C': 0.1, 'vect__max_df': 0.2, 'vect__mi...           0.621182   \n",
      "\n",
      "    split1_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0            0.645452       ...                0.650643        0.007689   \n",
      "1            0.608797       ...                0.609241        0.006882   \n",
      "2            0.641453       ...                0.649643        0.008873   \n",
      "3            0.606465       ...                0.607974        0.006930   \n",
      "4            0.636121       ...                0.640576        0.006544   \n",
      "5            0.599134       ...                0.598440        0.007991   \n",
      "6            0.651783       ...                0.655510        0.006978   \n",
      "7            0.623792       ...                0.626642        0.007638   \n",
      "8            0.650117       ...                0.655844        0.007509   \n",
      "9            0.621126       ...                0.626508        0.007544   \n",
      "10           0.646118       ...                0.650043        0.005160   \n",
      "11           0.619793       ...                0.616441        0.006935   \n",
      "12           0.613129       ...                0.617374        0.009408   \n",
      "13           0.616794       ...                0.619775        0.006485   \n",
      "14           0.613795       ...                0.617374        0.009012   \n",
      "15           0.618461       ...                0.620641        0.006679   \n",
      "16           0.611463       ...                0.611641        0.007972   \n",
      "17           0.610796       ...                0.613908        0.006915   \n",
      "\n",
      "    rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                 3            0.999917            0.999500   \n",
      "1                16            0.974472            0.977080   \n",
      "2                 5            0.999833            0.999500   \n",
      "3                17            0.974472            0.977746   \n",
      "4                 6            0.999499            0.999583   \n",
      "5                18            0.974139            0.975829   \n",
      "6                 2            0.995078            0.994166   \n",
      "7                 7            0.946108            0.948908   \n",
      "8                 1            0.995078            0.994416   \n",
      "9                 8            0.947526            0.948741   \n",
      "10                4            0.995912            0.995083   \n",
      "11               13            0.946359            0.947241   \n",
      "12               11            0.780929            0.781130   \n",
      "13               10            0.736715            0.741124   \n",
      "14               11            0.782348            0.783547   \n",
      "15                9            0.738634            0.742290   \n",
      "16               15            0.773755            0.774046   \n",
      "17               14            0.730375            0.732705   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0             0.999250            0.999667            0.999500   \n",
      "1             0.974835            0.976173            0.975431   \n",
      "2             0.999333            0.999667            0.999500   \n",
      "3             0.974835            0.976256            0.975348   \n",
      "4             0.999500            0.999583            0.999334   \n",
      "5             0.972752            0.974590            0.974931   \n",
      "6             0.994834            0.994585            0.993920   \n",
      "7             0.947421            0.950679            0.949113   \n",
      "8             0.994667            0.994418            0.993754   \n",
      "9             0.946671            0.951012            0.949113   \n",
      "10            0.994334            0.994335            0.994836   \n",
      "11            0.947254            0.948263            0.949280   \n",
      "12            0.784601            0.782471            0.784626   \n",
      "13            0.739522            0.740815            0.741401   \n",
      "14            0.786601            0.785220            0.785792   \n",
      "15            0.741855            0.741648            0.741734   \n",
      "16            0.775685            0.774973            0.775881   \n",
      "17            0.731772            0.735399            0.734322   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.999567         0.000220  \n",
      "1           0.975598         0.000938  \n",
      "2           0.999567         0.000170  \n",
      "3           0.975732         0.001172  \n",
      "4           0.999500         0.000091  \n",
      "5           0.974448         0.001013  \n",
      "6           0.994516         0.000424  \n",
      "7           0.948446         0.001560  \n",
      "8           0.994467         0.000431  \n",
      "9           0.948613         0.001482  \n",
      "10          0.994900         0.000583  \n",
      "11          0.947679         0.001002  \n",
      "12          0.782751         0.001610  \n",
      "13          0.739915         0.001725  \n",
      "14          0.784702         0.001545  \n",
      "15          0.741232         0.001318  \n",
      "16          0.774868         0.000851  \n",
      "17          0.732915         0.001786  \n",
      "\n",
      "[18 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.65064, std: 0.00769, params: {'svc__C': 2, 'vect__max_df': 0.4, 'vect__min_df': 0},\n",
      " mean: 0.60924, std: 0.00688, params: {'svc__C': 2, 'vect__max_df': 0.4, 'vect__min_df': 10},\n",
      " mean: 0.64964, std: 0.00887, params: {'svc__C': 2, 'vect__max_df': 0.3, 'vect__min_df': 0},\n",
      " mean: 0.60797, std: 0.00693, params: {'svc__C': 2, 'vect__max_df': 0.3, 'vect__min_df': 10},\n",
      " mean: 0.64058, std: 0.00654, params: {'svc__C': 2, 'vect__max_df': 0.2, 'vect__min_df': 0},\n",
      " mean: 0.59844, std: 0.00799, params: {'svc__C': 2, 'vect__max_df': 0.2, 'vect__min_df': 10},\n",
      " mean: 0.65551, std: 0.00697, params: {'svc__C': 1, 'vect__max_df': 0.4, 'vect__min_df': 0},\n",
      " mean: 0.62664, std: 0.00764, params: {'svc__C': 1, 'vect__max_df': 0.4, 'vect__min_df': 10},\n",
      " mean: 0.65584, std: 0.00751, params: {'svc__C': 1, 'vect__max_df': 0.3, 'vect__min_df': 0},\n",
      " mean: 0.62651, std: 0.00754, params: {'svc__C': 1, 'vect__max_df': 0.3, 'vect__min_df': 10},\n",
      " mean: 0.65004, std: 0.00516, params: {'svc__C': 1, 'vect__max_df': 0.2, 'vect__min_df': 0},\n",
      " mean: 0.61644, std: 0.00694, params: {'svc__C': 1, 'vect__max_df': 0.2, 'vect__min_df': 10},\n",
      " mean: 0.61737, std: 0.00941, params: {'svc__C': 0.1, 'vect__max_df': 0.4, 'vect__min_df': 0},\n",
      " mean: 0.61977, std: 0.00648, params: {'svc__C': 0.1, 'vect__max_df': 0.4, 'vect__min_df': 10},\n",
      " mean: 0.61737, std: 0.00901, params: {'svc__C': 0.1, 'vect__max_df': 0.3, 'vect__min_df': 0},\n",
      " mean: 0.62064, std: 0.00668, params: {'svc__C': 0.1, 'vect__max_df': 0.3, 'vect__min_df': 10},\n",
      " mean: 0.61164, std: 0.00797, params: {'svc__C': 0.1, 'vect__max_df': 0.2, 'vect__min_df': 0},\n",
      " mean: 0.61391, std: 0.00691, params: {'svc__C': 0.1, 'vect__max_df': 0.2, 'vect__min_df': 10}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PCnew\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of all the categories. I set this up to figure out which category only had 1 member and was gviing me an error. That is why above I removed the review pertaining to the category \"GOOD NEWS\". Since the error is fixed the code below is no longer serves a purpose but I left it just for completeness sake. GOOD NEWS won't appear below since I reran the cells, but it was there at first and this is how I figured out which one was screwing with my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "\n",
    "for x in y:\n",
    "    if x not in unique:\n",
    "        unique.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIME',\n",
       " 'ENTERTAINMENT',\n",
       " 'WORLD NEWS',\n",
       " 'IMPACT',\n",
       " 'POLITICS',\n",
       " 'WEIRD NEWS',\n",
       " 'BLACK VOICES',\n",
       " 'WOMEN',\n",
       " 'COMEDY',\n",
       " 'QUEER VOICES',\n",
       " 'SPORTS',\n",
       " 'BUSINESS',\n",
       " 'TRAVEL',\n",
       " 'MEDIA',\n",
       " 'TECH',\n",
       " 'RELIGION',\n",
       " 'SCIENCE',\n",
       " 'LATINO VOICES',\n",
       " 'EDUCATION',\n",
       " 'COLLEGE',\n",
       " 'PARENTS',\n",
       " 'ARTS & CULTURE',\n",
       " 'STYLE',\n",
       " 'GREEN',\n",
       " 'TASTE',\n",
       " 'HEALTHY LIVING',\n",
       " 'THE WORLDPOST']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the list of all the categories\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 0,\n",
       " 'CRIME': 0,\n",
       " 'ENTERTAINMENT': 0,\n",
       " 'WORLD NEWS': 0,\n",
       " 'IMPACT': 0,\n",
       " 'POLITICS': 0,\n",
       " 'WEIRD NEWS': 0,\n",
       " 'BLACK VOICES': 0,\n",
       " 'WOMEN': 0,\n",
       " 'COMEDY': 0,\n",
       " 'QUEER VOICES': 0,\n",
       " 'SPORTS': 0,\n",
       " 'BUSINESS': 0,\n",
       " 'TRAVEL': 0,\n",
       " 'MEDIA': 0,\n",
       " 'TECH': 0,\n",
       " 'RELIGION': 0,\n",
       " 'SCIENCE': 0,\n",
       " 'LATINO VOICES': 0,\n",
       " 'EDUCATION': 0,\n",
       " 'COLLEGE': 0,\n",
       " 'PARENTS': 0,\n",
       " 'ARTS & CULTURE': 0,\n",
       " 'STYLE': 0,\n",
       " 'GREEN': 0,\n",
       " 'TASTE': 0,\n",
       " 'HEALTHY LIVING': 0,\n",
       " 'THE WORLDPOST': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dict to hold counts\n",
    "catd = {\"test\" :0}\n",
    "for item in unique:\n",
    "    catd.update( {str(item) : 0})\n",
    "catd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 0,\n",
       " 'CRIME': 339,\n",
       " 'ENTERTAINMENT': 3050,\n",
       " 'WORLD NEWS': 1487,\n",
       " 'IMPACT': 256,\n",
       " 'POLITICS': 7007,\n",
       " 'WEIRD NEWS': 385,\n",
       " 'BLACK VOICES': 766,\n",
       " 'WOMEN': 604,\n",
       " 'COMEDY': 856,\n",
       " 'QUEER VOICES': 1023,\n",
       " 'SPORTS': 517,\n",
       " 'BUSINESS': 240,\n",
       " 'TRAVEL': 163,\n",
       " 'MEDIA': 575,\n",
       " 'TECH': 104,\n",
       " 'RELIGION': 200,\n",
       " 'SCIENCE': 74,\n",
       " 'LATINO VOICES': 223,\n",
       " 'EDUCATION': 133,\n",
       " 'COLLEGE': 18,\n",
       " 'PARENTS': 501,\n",
       " 'ARTS & CULTURE': 106,\n",
       " 'STYLE': 292,\n",
       " 'GREEN': 290,\n",
       " 'TASTE': 212,\n",
       " 'HEALTHY LIVING': 546,\n",
       " 'THE WORLDPOST': 32}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in y:\n",
    "    catd[x] += 1\n",
    "catd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
